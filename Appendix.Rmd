---
title: "Appendix"
output: word_document
---

## 0- Preliminaries

First we load in the data and look at a summary of it.
```
load("TeleChurn.rdata")
summary(TeleChurn)
head(TeleChurn)
```
Then we install all the packages we need
```
library(car)
library(olsrr)
library(VIM)
library(ggplot2)
library(relaimpo)
library(caret)
library(MASS)
library(gglasso)
library(glmnet)
library(Stat2Data)
library(pROC)
library(rgl)
library(reshape)
library(gclus)
library(sm)
library(ggpubr)
library(plyr)
library(leaps)
library(calibrate)
library(yardstick)
library(Information)
library(ggcorrplot)
library(corrplot)
library(dplyr)
```
Then we set all the factor variables as factors. For example 'Complains':
```
TeleChurn$Complains <- as.factor(TeleChurn$Complains)
```

## 1- Splitting the data
```
set.seed(123)
n_train <- 0.7 * nrow(TeleChurn) #sets 70% of the data as training and hence 30% for validation
train_indices <- sample(3150, size = n_train, replace = FALSE)
train <- TeleChurn[train_indices, ]
valid <- TeleChurn[-train_indices, ]
attach(train)
```

## 2- EDA
First we look at the response variable
```
ggplot(TeleChurn, aes(x = Churnfactor)) + 
  geom_bar(fill="orange") +
  ggtitle("Bar graph of customers who 'Churn'") +
  labs(y= "Amount of customers", x= "Churn")
table(TeleChurn$Churn)
```
Then we look at all the continuous explanatory variables.
For example CallFailure:
```
ggplot(train, aes(x = Churnfactor, y = CallFailure)) + 
  geom_boxplot()
hist(CallFailure)
```
Then we look at the factor explanatory variables.
For example Complains:
```
table(Complains)
plot(Complains, Churnfactor)
```
Then we look at the correlation matrix of the explanatory variables.
```
corrdata<- apply(train, 2, as.numeric)
corrdata <- corrdata[, -ncol(corrdata)]
corrdata1 <- corrdata
corrdata <- corrdata[, -ncol(corrdata)]
corr_matrix <- cor(corrdata)
ggcorrplot(corr_matrix, 
           hc.order = TRUE, 
           type = "lower", 
           outline.color = "white", 
           colors = c("blue", "white", "red"), 
           ggtheme = ggplot2::theme_classic(), 
           lab = TRUE)
```
Then we look at the correlation between the response and explanatory variables.
```
corr_matrix1 <- cor(corrdata1)
corr_matrix2 <- corr_matrix1[,ncol(corr_matrix1)]
corr_matrix2 <- corr_matrix2[-13]
bar_heights <- barplot(corr_matrix2, 
                       horiz = TRUE,
                       main = "Correlation values of Churn with explanatory variables", 
                       xlab = "Correlation", 
                       xlim = c(-1, 1), 
                       col = "purple", 
                       border = NA,
                       yaxt = "n")
text(x = -1, 
     y = bar_heights, 
     labels = names(corr_matrix2), 
     pos = 4, 
     col = "black", 
     cex = 0.9, 
```
Then we plot the conditional densities using ggplot
```
TeleChurn.long <- melt(TeleChurn[,c(1:11,14)], id="Churnfactor")
ggplot(aes(x=value, group=Churnfactor, col=factor(Churnfactor)), data=TeleChurn.long) +
  geom_density() + facet_wrap(~ variable, scales="free")
```
Then using the sm package. For example CallFailure:
```
sm.density.compare(CallFailure, Churn)
title(main="CallFailure against churn")  
```
Then we look at a barchart of churn vs not churn.
```
barplot(prop.table(summary(Churnfactor)),col="red",main="Bar Chart of Churn Test",
        ylab="Proportion of units in study",xlab="Result of Test for Churn", ylim=c(0,1),
        axis.lty=1)
```
Then we look at conditional density plots for the continuous explanatory variables. For example CallFailure:
```
ggplot(TeleChurn, aes(x = Complains, fill = Churnfactor)) + 
  geom_density(alpha = 0.5) +
  ggtitle("Conditional Density Plot of complains by Churn Status")
```
Then we look at the empirical logits.
```
# function to calculate bins
cut.equal <- function(x, N) {
  breaks <- quantile(x, seq(from=0, to=1, length=N+1))
  cut(x, unique(breaks))
}

## Empirical logits
emplogit <- function(x, y, ngroups, ...) {
  xgroup <- cut.equal(x, ngroups)
  xmean <- tapply(x, INDEX=xgroup, FUN=mean)
  ylogit <- tapply(y, INDEX=xgroup, FUN = function(y) {
    log(sum(y) + 0.5) - log(sum(1-y) + 0.5)
  })
  plot(xmean, ylogit, ylab='empirical logit',...)
}

par(mfrow=c(3,3), mar=c(4.1, 4.1, 2.1, 2.1))
nam <- colnames(TeleChurn)
for (k in c(1,3,5,6,7,8)){
  emplogit(TeleChurn[,k], as.numeric(TeleChurn[,13]), ngroups=15, main=nam[k], type="b", pch=16)
}
par(mfrow=c(1,1))
barplot(prop.table(summary(Churnfactor)),col="red",main="Bar Chart of churn Test",
        ylab="Proportion of people who churn",xlab="Result of Test for churn", ylim=c(0,1),
        axis.lty=1)

# Method 2 for empirical logit:
myemplogit <- function(yvar=y,xvar=x,maxbins=10,sc=1,line=TRUE,...){
  breaks  <<- unique(quantile(xvar, probs=0:maxbins/maxbins))
  levs  <<- (cut(xvar, breaks, include.lowest=FALSE))
  num <<- as.numeric(levs)
  c.tab <- count(num,'levs')
  c.tab$levs <- factor(c.tab$levs, levels = levels(addNA(c.tab$levs)), labels = c(levels(c.tab$levs),
                                                                                  paste("[",min(xvar),"]",sep="")), exclude = NULL)
  c.tab <- c.tab[c(nrow(c.tab),1:nrow(c.tab)-1),]
  sc <- (max(c.tab$freq)/min(c.tab$freq)/sc)^2
  zcex <<- sqrt(c.tab$freq/pi)/sc
  print(c.tab);print(zcex);print(sc)
  emplogitplot1(yvar~xvar,breaks=breaks,cex=1,showline=line,...)
}
```
And view these, e.g. for CallFailure:
```
myemplogit(Churnfactor,CallFailure,30,sc=30,xlab="Call Failures")
```
Then we create a function for the conditional histograms.
```
#Define Colours
myblue <- rgb(0, 0, 255, max = 255, alpha = 125, names = "blue50")
myred <- rgb(255, 0, 0, max = 255, alpha = 125, names = "red50")
myboth <- rgb(191, 66, 130, max = 255, alpha = 255, names = "rednblue50")
#Function for conditional histograms
conHist <- function(yvar=y,xvar=x,br=18,yvar1=0,yvar2=1,leg=FALSE,xxlab=deparse(substitute(xvar)),cex.l=1,cex.a=1,title="",cex.m=1,...){
  h1 <-  graphics::hist(xvar[yvar==yvar1],plot=FALSE,breaks=br)
  h2 <-  graphics::hist(xvar[yvar==yvar2],plot=FALSE,breaks=br)
  mxy <- max(max(h1$density),max(h2$density))
  mxx <- max(c(max(h1$breaks),max(h2$breaks)))
  mnx <- min(c(min(h1$breaks),min(h2$breaks)))
  graphics::hist(xvar[yvar==yvar1],xlab=xxlab,prob=TRUE,col=myblue,
                 breaks=br,
                 ylim=c(0,mxy),xlim=c(mnx,mxx),cex.lab=cex.l,cex.axis=cex.a,cex.main=cex.m,main=title)
  graphics::hist(xvar[yvar==yvar2],xlab="",prob=TRUE,col=myred,
                 breaks=br,main="",
                 ylim=c(0,my),xlim=c(0,mx),add=TRUE)
  if (leg){
    legend('topright',legend=c(yvar2,yvar1,"overlap"),col=c(myred,myblue,myboth),pch=15,pt.cex=2)
  }
}
```
Then view these, e.g. for CallFailure:
```
conHist(Churnfactor, CallFailure,leg=TRUE,yvar1="Not Churn",yvar2="Churn",cex.l=1.5,cex.a=1.5,title="Conditional Histogram Call Failure",cex.m=1)
```
Then we put these plots together
```
plotall <- function(yvar=y,xvar=x,br=br,yvar1=0,yvar2=1,leg=TRUE,maxbins=10,sc=1,line=TRUE,xxlab=deparse(substitute(xvar)),yylab="y",Title=xxlab,...){
  par(mfrow=c(1,4),mgp=c(1.7,0.7,0),mar=c(3.5,3.5,1,1),oma=c(1,1,2.5,0))
  hist(xvar,col="blue",main="",xlab=xxlab)
  boxplot(xvar~yvar,xlab = yylab,ylab = xxlab, col="blue")
  conHist(yvar,xvar,leg=leg,yvar1=yvar1,yvar2=yvar2,xxlab=xxlab,br=br) 
  sm.density.compare(xvar,yvar)
  title(main="")
  colfill<-c(2:(2+length(levels(yvar))))
  if(leg){
    legend("topright", levels(yvar), fill=colfill)
  }  
  myemplogit(as.numeric(yvar)-1,xvar,maxbins,sc=sc,xlab=xxlab)
  emplogit(xvar, as.numeric(yvar)-1, ngroups=15, main="", type="b", pch=16)
  mtext(Title, side = 3, line = 0, outer = TRUE,cex=1.8)
} 
```
This allows us to investigate transformations so we evaulate these.
e.g. for CallFailure:
```
plotall(Churnfactor,CallFailure,br=30,maxbins=30,yvar1="Not Churn",yvar2="Churn",leg=TRUE,sc=30, yylab = "CHURN",xxlab="Call Failures")  
plotall(Churnfactor,sqrt(CallFailure),br=30,maxbins=30,yvar1="Not Churn",yvar2="Churn",leg=TRUE,sc=30, yylab = "CHURN",xxlab="Call Failures")  
plotall(Churnfactor,log(CallFailure),br=30,maxbins=30,yvar1="Not Churn",yvar2="Churn",leg=TRUE,sc=30, yylab = "CHURN",xxlab="Call Failures")  
# here log looks best but also include original
```

## 3- Fitting models
Fitting the initial model and performing checks on it:
```
# initial model:
model1 <- glm(Churnfactor~ CallFailure+log(CallFailure+0.5)+SubscriptionLength+(SubscriptionLength^2)+
                SecondsOfUse+sqrt(SecondsOfUse)+FrequencyOfUse+sqrt(FrequencyOfUse)+
                I(FrequencyOfSMS^(1/3))+DistinctCalledNumbers+sqrt(DistinctCalledNumbers)+
                Complains+TariffPlan+Status+ChargeAmount+AgeGroup,family = "binomial")

# would be nice to do a turkey transformation test for subscription length but dont have time

# brief evaluation of initial model:
summary(model1)
anova(model1)

# multicollinearity check for initial model:
vif(model1)
# large amount of multicollinearity for variables: SecondsOfUse, FrequencyOfUSe and DistinctCalledNumbers
```
Then create the LASSO model:
```
# Automated approach to reduce the model- LASSO:
# Convert the data to a matrix format
X <- model.matrix(model1)[,-1]

# Fit a Lasso model using cross-validation
cv_model <- cv.glmnet(X, Churnfactor, family = "binomial", alpha = 1)

# Get the optimal value of lambda
lambda_opt <- cv_model$lambda.min

# Fit a Lasso model using the optimal lambda
lasso_model <- glmnet(X, Churnfactor, family = "binomial", alpha = 1, lambda = lambda_opt)

# Get the coefficients of the Lasso model
lasso_coef <- coef(lasso_model)

# Print the coefficients of the Lasso model
print(lasso_coef)

# this gives us our second model:

model2 <- glm(Churnfactor~ CallFailure+log(CallFailure+0.5)+SubscriptionLength+(SubscriptionLength^2)+
                sqrt(SecondsOfUse)+FrequencyOfUse+sqrt(FrequencyOfUse)+I(FrequencyOfSMS^(1/3))+
                DistinctCalledNumbers+sqrt(DistinctCalledNumbers)+Complains+TariffPlan+Status+ChargeAmount+
                AgeGroup,family = "binomial")
```
Then create the step model:
```
# Now use shrinkage approach to reduce the model- using AIC and BIC
model_aic <- stepAIC(model1, direction = "both", trace = FALSE, k = log(nrow(train)))
selected_aic <- names(coef(model_aic)[-1][which(coef(model_aic)[-1] != 0)])

# Perform stepwise selection with BIC
model_bic <- stepAIC(model1, direction = "both", trace = FALSE, k = log(nrow(train)), AIC = FALSE)
selected_bic <- names(coef(model_bic)[-1][which(coef(model_bic)[-1] != 0)])

# Combine selected variables
selected_vars <- unique(c(selected_aic, selected_bic))
selected_vars

# Build final model with selected variables

model3 <- glm(Churnfactor~ log(CallFailure+0.5)+SubscriptionLength+
                SecondsOfUse+sqrt(SecondsOfUse)+FrequencyOfUse+sqrt(FrequencyOfUse)+
                I(FrequencyOfSMS^(1/3))+DistinctCalledNumbers+sqrt(DistinctCalledNumbers)+
                Complains+Status,family = "binomial")
```
Then we perform interim checks of these 3 models:
```
# Model1:
plot(model1)
vif(model1)
# Model2:
plot(model2)
vif(model2)
# Model3:
plot(model3)
vif(model3)
```
Then we create the profit function and evaluate the models using this.
```
# Profit function
evaluate_profit <- function(model, data) {
  # Make predictions for the test data
  prob_churn <- predict(model, newdata = data, type = "response")
  predicted_churn <- ifelse(prob_churn >= 0.5, 1, 0)
  
  # Calculate profit for each customer
  profit <- ifelse(predicted_churn == 1 & data$Churn == 1, 0.6 * data$CustomerValue - 70,
                   ifelse(predicted_churn == 0 & data$Churn == 0, data$CustomerValue - 70,
                          ifelse(predicted_churn == 0 & data$Churn == 1, 0,
                                 ifelse(predicted_churn == 1 & data$Churn == 0, data$CustomerValue, 0))))

  churnchurn <- sum(predicted_churn == 1 & data$Churn == 1)
  predchurnaccnot <- sum(predicted_churn == 1 & data$Churn == 0)
  prednotaccchurn <- sum(predicted_churn == 0 & data$Churn == 1)
  notnot <- sum(predicted_churn == 0 & data$Churn == 0)
  
# Calculate total profit
total_profit <- sum(profit)

# Return total profit
print(churnchurn)
print(predchurnaccnot)
print(prednotaccchurn)
print(notnot)
return(total_profit)

}

# now test for our models:
evaluate_profit(model1, valid)
evaluate_profit(model2, valid)
evaluate_profit(model3, valid)
# model2 has highest profit but very small difference
```
Then we look at ROC for the models and evaluate them using AUC:
```
# Now look at ROC curves:
roc_model1 <- roc(valid$Churnfactor, predict(model1, newdata = valid, type = "response"))
roc_model2 <- roc(valid$Churnfactor, predict(model2, newdata = valid, type = "response"))
roc_model3 <- roc(valid$Churnfactor, predict(model3, newdata = valid, type = "response"))
# Create an empty plot with the appropriate axes labels and title
plot(0, 0, type = "n", xlim = c(0, 1), ylim = c(0, 1),
     xlab = "False Positive Rate", ylab = "True Positive Rate",
     main = "ROC Curve for candidate models")

# Add the ROC curve for model1 in red
lines(roc_model1, col = "red")

# Add the ROC curve for model2 in blue
lines(roc_model2, col = "blue")

# Add the ROC curve for model3 in green
lines(roc_model3, col = "green")

# Add a legend to the plot
legend("bottomleft", legend = c("Initial model", "LASSO model", "Step model"),
       col = c("red", "blue", "green"), lty = 1)

# For model1:
auc_model1 <- auc(roc_model1)
auc_model1
# For model2:
auc_model2 <- auc(roc_model2)
auc_model2
# For model3:
auc_model3 <- auc(roc_model3)
auc_model3
# all 3 models have extrmely similar AUC 
```
Then we create an intercetion model of these 3 and check multicollinearity.
```
model4 <- glm(Churnfactor~ log(CallFailure+0.5)+SubscriptionLength+
                     SecondsOfUse+sqrt(SecondsOfUse)+FrequencyOfUse+sqrt(FrequencyOfUse)+
                     I(FrequencyOfSMS^(1/3))+DistinctCalledNumbers+sqrt(DistinctCalledNumbers)+
                     Complains+Status,family = "binomial")


# Multicollinearity was previously an issue so lets investigate this further
vif(model4)
plot(vif(model4))
barplot(vif(model4))

vif_values4 <- vif(model4)
vif_threshold <- 10
barplot(vif_values4,
        col = ifelse(vif_values4 > vif_threshold, "red", "green"), 
        ylim = c(0, max(vif_values4)*1.2))
abline(h = vif_threshold, col = "blue", lty = 2)
title(main = "VIF for Intersection Model")
xlabel <- "Variable"
ylabel <- "VIF"
title(xlab = xlabel, ylab = ylabel)

barplot(vif(model4), ylim = c(0, max(vif_values4)*1.2),
        ylab = "VIF",
        xlab= "Variables",
        main = "VIF for Intersection Model", 
        col = ifelse(vif_values4 > 10, "red", "green"), las = 2, names.arg=F)
abline(h = 10, lty = 2, col = "blue")
# From this we can see that all the variables with more than one version present have a high VIF
# So lets see what the most important level is
coef(model4)
```
Then create the final model and evaluate it:
```
finalmodel <- glm(Churnfactor~ log(CallFailure+0.5)+SubscriptionLength+
                    sqrt(SecondsOfUse)+sqrt(FrequencyOfUse)+
                    I(FrequencyOfSMS^(1/3))+sqrt(DistinctCalledNumbers)+
                    Complains+Status,family = "binomial")

finalvif <- vif(finalmodel)
barplot(vif(finalmodel), ylim = c(0, max(finalvif)*1.2),
        ylab = "VIF",
        xlab= "Variables",
        main = "VIF for Final Model", 
        col = ifelse(finalvif > 10, "red", "green"), las = 2, names.arg=F)
abline(h = 10, lty = 2, col = "blue")
roc_finalmodel <- roc(valid$Churnfactor, predict(finalmodel, newdata = valid, type = "response"))
auc(roc_finalmodel)
# Still an extremely high AUC with only a 0.03% decrease from the previously best performing model
evaluate_profit(finalmodel, valid)
# The predicted profit is also extremely similar to the previous models
# therefore we will take this as our final model
```

## 5- Interpreting the final model
Look at the parameter estimates for the final model.
```
coef(finalmodel)
```
Then we calculate the logodds and probability for the example.
```
logodds <- 0.423940290 + 0.699755583*log(10+0.5) + -0.039028663*20 + 0.004836548*sqrt(4000) + -0.482606961*sqrt(80) + -0.237179669*(70^(1/3)) + 0.005965162*sqrt(10) + 4.112926465 + 1.783546295*0
logodds
prob <- exp(logodds)/(1+exp(logodds))
prob
```

## 6- Validating the final model
Precision- recall plot:
```
# Predict on validation set
pred <- predict(finalmodel, type = "response", newdata = valid)
# Create ROC object
pr <- roc(valid$Churnfactor, pred, plot = FALSE)
# Plot precision-recall curve
plot(pr, col = "blue", main = "Precision-Recall Curve", xlab= "Recall", ylab= "Precision", xlim=c(0,1), ylim=c(0,1))
# this is ideal
```
Calibration plot:
```
# predict on the validation set
valid$pred <- predict(finalmodel, newdata = valid, type = "response")
# create bins for predictions
bin_valid <- cut(valid$pred, breaks = seq(0, 1, by = 0.05))
# calculate mean predicted probability and observed outcome for each bin
calib_data <- aggregate(cbind(pred = pred, Churnfactor = (as.numeric(Churnfactor)-1)) ~ bin_valid, valid, 
                        FUN = function(x) c(mean(x), sum(x)))
# create calibration plot
ggplot(calib_data, aes(x = pred[, 1], y = Churnfactor[, 1])) + 
  geom_point() + 
  geom_smooth(method = "lm", se = FALSE, fullrange = TRUE) +
  labs(x = "Mean predicted probability", y = "Observed outcome rate")+
  geom_abline(linetype = "dashed") +
  ggtitle("Calibration Plot")
  ```